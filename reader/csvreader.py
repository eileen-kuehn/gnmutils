import logging
import re
import gzip
import os

from gnmutils.reader.datareader import DataReader
from gnmutils.monitoringconfiguration import MonitoringConfiguration


class CSVReader(DataReader):
    """
    Main class that takes care to read CSV files generated by different tools in my dissertation environment.
    It automatically removes comments, is able to detect specific comments from GNM tool to set version and
    configuration environment, detects headers from CSV, and removes commas from command strings, if available.

    References to the actual parser and also the operator can be given. The parser as well as operator default
    to `None`.

    :param parser: the parser to be used for processing the rows
    :type parser: :py:class:`ProcessParser`, :py:class:`gnmutils.jobparser.JobParser`, :py:class:`TrafficParser`, or None
    """
    def __init__(self, parser=None):
        DataReader.__init__(self, parser=parser)
        # caches the different header fields
        self._header = None
        self._tme = None

    @property
    def parser(self):
        """
        This methods returns the parser that is currently in use for parsing the valid rows found in CSV.

        :return: parser being used for row parsing
        :rtype: :py:class:`JobParser`, :py:class:`ProcessParser` or :py:class:`TrafficParser`
        """
        return self._parser

    @parser.setter
    def parser(self, value):
        """
        Setting the actual subclass of :py:class:`DataReader`.

        :param value: the parser to be used
        :type value: Instance of subclass of :py:class:`DataReader`
        """
        self._parser = value

    # prepare for next CSV file to be read
    def clearCaches(self):
        """
        Method explicitly clears the available caches.
        """
        del self._header
        self._header = None
        self._tme = None
        if self._parser:
            self._parser.clearCaches()

    def data(self, path=None):
        self._header = None
        openFunction = open
        if re.match(".*.gz$", path):
          openFunction = gzip.open
        if path in self._parser.parsed_data:
            yield None
        else:
            logging.getLogger(self.__class__.__name__).info("starting to read %s" % path)
            with openFunction(path, 'r') as csvfile:
                tme = 0
                # process every line in csvfile
                for idx, line in enumerate(csvfile):
                    # first check for comments in CSV line and skip
                    if line[0] == "#":
                        # check if it is a line specifying the version of monitoring tool
                        if line.startswith("# version"):
                            try:
                                configDict = dict(((val.strip() for val in values.split(":"))
                                                   for values in line[1:].split(",")))
                                configuration = MonitoringConfiguration(**configDict)
                                self._parser.configuration = configuration
                            except KeyError:
                                pass
                        continue

                    # remove newline character from line
                    line = line[:-1]
                    try:
                        # as long as the header has not been initialized,
                        # an exception is thrown and the header row is deteced
                        # otherwise the usual processing process starts
                        tme = line.split(",")[self._header['tme']] or self._tme or tme
                        self._tme = int(tme)
                    except TypeError:
                        # initialize the header cache
                        row = line.split(",")
                        # check if maybe no header is included
                        if "tme" not in row[0]:
                            self._header = self._parser.defaultHeader(length=len(row))
                        else:
                            headerCache = {}
                            for index, item in enumerate(line.split(",")):
                                headerCache[item] = index
                            self._header = headerCache
                            continue
                    except ValueError:
                        # current line is header line
                        headerCache = {}
                        for index, item in enumerate(line.split(",")):
                            headerCache[item] = index
                        self._header = headerCache
                        continue
                    while True:
                        try:
                            row = line.split(",")
                            # check if there are too many header fields than expected
                            if len(row) > len(self._header):
                                logging.info(
                                    "Trying to fix wrong row length: row %d (%s:%d - %s) vs. header %d" % (
                                        len(row), path, idx, line, len(self._header))
                                )
                                # check if additional "," are in command and remove
                                while len(row) > len(self._header):
                                    cmdIndex = self._header["cmd"]
                                    cmdString = row[cmdIndex] + row[cmdIndex+1]
                                    del row[cmdIndex+1]
                                    row[cmdIndex] = cmdString
                            # finally add the valid row to the parser
                            tme_in_row = row[self._header["tme"]]
                            if tme_in_row is None or len(tme_in_row) == 0:
                                row[self._header["tme"]] = self._tme
                            data_dict = {}
                            for key in self._header:
                                data_dict[key] = row[self._header[key]]
                            yield data_dict
                        except IndexError as e:
                            line = (line + csvfile.next())[:-1]
                        except StopIteration as e:
                            logging.getLogger(self.__class__.__name__).error(
                                "there seems to be a wrong ending in the file for line %d (%s) in file %s" % (
                                    idx, line, path)
                            )
                        else:
                            break
            self._parser.parsed_data.add(path)
